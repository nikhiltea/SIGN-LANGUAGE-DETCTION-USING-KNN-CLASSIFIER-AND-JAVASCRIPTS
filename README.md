# SIGN-LANGUAGE-DETCTION-USING-KNN-CLASSIFIER-AND-JAVASCRIPTS
# Sign Language Translator

This project is a real-time sign language translator that uses a webcam to capture hand gestures and a k-Nearest Neighbors (k-NN) algorithm to classify them into corresponding words.  The project is built using JavaScript, TensorFlow.js, and the deeplearn-knn-image-classifier library.

## Features

* *Real-time Gesture Recognition:*  Captures video from the webcam and analyzes hand gestures in real-time.
* *k-NN Classification:*  Uses a k-Nearest Neighbors algorithm to classify the hand gestures.
* *Customizable Gestures:* Allows users to train the model with custom gestures and words.
* *Text Output:* Displays the translated words as text on the screen.
* *Speech Synthesis:*  Speaks the translated words using the browser's text-to-speech capabilities (SpeechSynthesis API).
* *User-Friendly Interface:*  Provides a simple and intuitive user interface for training and using the translator.

## Technologies Used

* *JavaScript:*  The primary programming language for the project.
* *TensorFlow.js:* A JavaScript library for training and running machine learning models in the browser.
* **deeplearn-knn-image-classifier:** A library that simplifies the implementation of k-NN image classification with TensorFlow.js.
* *HTML & CSS:*  Used for building the user interface.

## Setup and Installation

1. *Clone the Repository:*
   ```bash
   git clone <repository_url>
   cd sign-language-translator
